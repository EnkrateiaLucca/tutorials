{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and restoring tensorflow models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of a tensorflow model:\n",
    "    - Meta graph\n",
    "        - A protocol buffer which saves the complete tensorfolow graph with all the variables, operations, collections, etc... The extension is \".meta\"\n",
    "    - Checkpoint file\n",
    "        - Binary file which contains all the values of the weights, biases, gradients and all the other variables saved. Extension: \".ckpt\" (there has been an alterations, now we have two files: .data-0000-of-0001 and .index)\n",
    "        - .data contains our training variables\n",
    "        - It also has a file named \"checkpoint\" which simply keeps a record of latest checkpoint files saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving a tensorflow model\n",
    "    - Create an instance of the tf.train.Saver() class\n",
    "    - Save the model variables from inside the session\n",
    "    - If we are saving after a certain number of training steps we set\n",
    "      the parameter: \"global_step\" to that number \n",
    "    - We dont need to save the meta file at every step because the basics parameters will not change across itarations so we can set the parameter in saver to false as shown below\n",
    "    - We can also specify which variables of the model we want to save\n",
    "    by setting the variables as elements in a list when instantiating the Saver class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_model.data-00000-of-00001', 'test_model.index', 'checkpoint', 'test_model.meta']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "w1 = tf.placeholder(\"float\", name = \"w1\")\n",
    "w2 = tf.placeholder(\"float\", name = \"w2\")\n",
    "b1 = tf.Variable(2.0, name = \"bias\")\n",
    "op_add = tf.add(w1,w2, name = \"op_add\")\n",
    "op_multiply = tf.multiply(op_add, b1, \"op_multiply\")\n",
    "feed_dict = {w1: 3.0, w2: 4.0}\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.save(sess, \"./test_model/test_model\")\n",
    "\n",
    "# To print the list of files in the \n",
    "# directory with the elements of the model\n",
    "print(os.listdir(\"./test_model/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_test_model-10'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To avoid saving the meta file we do this\n",
    "saver.save(sess, \"./my_test_model\", global_step=10, write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T keep only the last 4 models and to set the saving according \n",
    "# to a certain number of hours we set the parameters when we instantiate \n",
    "# the Saver() class\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=4, keep_checkpoint_every_n_hours=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Variable to save is not a Variable: Tensor(\"w2:0\", dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c1d5ef3e4024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To save specific variables we do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1100\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[1;32m   1152\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    771\u001b[0m                        \" when eager execution is not enabled.\")\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \"\"\"\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m       \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_1/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[0;34m(op_list, convert_variable_to_tensor)\u001b[0m\n\u001b[1;32m    563\u001b[0m               \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_convert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IsVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Variable to save is not a Variable: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ReadVariableOp\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Variable to save is not a Variable: Tensor(\"w2:0\", dtype=float32)"
     ]
    }
   ],
   "source": [
    "# To save specific variables we do\n",
    "\n",
    "saver = tf.train.Saver([w1,w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing a pre-trained model\n",
    "\n",
    "- Create the network\n",
    "- Load the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph(\"my_test_model-1000.meta\")\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint(\"./\"))\n",
    "    print(sess.run(\"w1:0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with restored models (a template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./my_test_model/my_test_model-1000'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define the variables of my network\n",
    "\n",
    "# Prepare to feed input, meaning: feed_dict and placeholders\n",
    "w1 = tf.placeholder(\"float\", name = \"w1\")\n",
    "w2 = tf.placeholder(\"float\", name = \"w2\")\n",
    "b1= tf.Variable(2.0, name = \"bias\")\n",
    "feed_dict = {w1:4, w2:8}\n",
    "\n",
    "# Define the test operation that we will restore and the session\n",
    "w3 = tf.add(w1, w2)\n",
    "w4 = tf.multiply(w3, b1,name = \"op_to_restore\")\n",
    "sess = tf.Session()\n",
    "var_initializer = tf.global_variables_initializer()\n",
    "sess.run(var_initializer)\n",
    "\n",
    "# Create a saver object which will save all the variables\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Run the operation by feeding the input (will print 24)\n",
    "\n",
    "print(sess.run(w4, feed_dict))\n",
    "\n",
    "# Now, save the graph\n",
    "saver.save(sess, \"./my_test_model/my_test_model\", global_step = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To restore the model we want to also prepare a new feed_dict the will\n",
    "feed the new training data to the network.\n",
    "To get the reference to these saved operations and placeholder variables we use \"graph.get_tensor_by_name()\":\n",
    "\n",
    "Example_1: w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "\n",
    "Example_2: op_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_model/test_model\n",
      "480.0\n"
     ]
    }
   ],
   "source": [
    "# Restoring and retraining\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "sess=tf.Session()\n",
    "# get metagraph and restore the weights\n",
    "saver = tf.train.import_meta_graph(\"./test_model/test_model.meta\")\n",
    "saver.restore(sess, tf.train.latest_checkpoint(\"./test_model/\"))\n",
    "\n",
    "# Now access and create placeholders and variables\n",
    "# and create a new feed dict do feed the new data\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "feed_dict = {w1:13.0, w2:17.0}\n",
    "op_to_restore = graph.get_tensor_by_name(\"op_multiply:0\")\n",
    "\n",
    "#Add more to the current graph\n",
    "\n",
    "add_on_top = tf.multiply(op_to_restore, 2)\n",
    "\n",
    "add_on_another_top = tf.multiply(add_on_top, 4)\n",
    "\n",
    "print(sess.run(add_on_another_top, feed_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more specific about what you want to restore and add to you can restor part of an old grpah and add on top of that to fine tune using grpah.get_tensor_by_name(), lets look at an example loading from the vgg model. \n",
    "\n",
    "WARNING: Do not run this example because we do not have the vgg model data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_vgg() missing 2 required positional arguments: 'sess' and 'vgg_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-44774d5e4e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mload_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: load_vgg() missing 2 required positional arguments: 'sess' and 'vgg_path'"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph('vgg.meta')\n",
    "# Access the graph\n",
    "graph = tf.get_default_graph()\n",
    "## Prepare the feed_dict for feeding data for fine-tuning \n",
    " \n",
    "#Access the appropriate output for fine-tuning\n",
    "fc7= graph.get_tensor_by_name('fc7:0')\n",
    " \n",
    "#use this if you only want to change gradients of the last layer\n",
    "fc7 = tf.stop_gradient(fc7) # It's an identity function\n",
    "fc7_shape= fc7.get_shape().as_list()\n",
    " \n",
    "new_outputs=2\n",
    "weights = tf.Variable(tf.truncated_normal([fc7_shape[3], num_outputs], stddev=0.05))\n",
    "biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "output = tf.matmul(fc7, weights) + biases\n",
    "pred = tf.nn.softmax(output)\n",
    " \n",
    "# Now, you run this with fine-tuning data in sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
